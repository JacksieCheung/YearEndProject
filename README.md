# YearEndProject

年终项目由 2019年 开始写，由张可学长带着我写了第一版。

2020年 我自发重构，写了现在的这个版本。

**年终项目的组成：**

年终项目由爬虫和接口两部分组成。

前者获取数据。由于学校的接口非常不稳定，而且很可能会修复漏洞，这里建议负责人每月爬一次，避免不必要的麻烦。爬虫部分使用了并发，爬一个月不会很慢的。

后者给前端获取数据。数据库的数据量一上来，接口的性能就成为了首要指标。这个版本也采用了并发模式，性能尚可，但我认为中间每个页面的计算逻辑还有很大优化空间。

**年终项目的目录：**

两者的目录文件比较相似，都仿照了工作台的目录。这里简单介绍以下每个文件夹，方便阅读：

```go
project // 项目名，爬虫叫 crawler, 接口叫 service
  |
  |___conf // 配置文件夹，程序开始前从这里读取数据。配置文件一般为 config.yaml
  |
  |___config // 放读取配置文件的代码
  |
  |___handler // 放置主要逻辑函数，并发放在这里
  |
  |___log // 日志代码
  |
  |___logs // 运行时输出的日志
  |
  |___model // 模型，放结构体和他们的方法。还有一些相关的功能函数
  |
  |———pkg // 工具包，有错误处理相关代码和用户验证相关代码
  |
  |___router // 中间件和路由分组的函数，爬虫没有接口服务，固没有该文件夹
```

**年终项目的大概逻辑**

* crawler：

爬数据->正则表达式处理->写入数据库

并发相关的逻辑得自己研究代码了

*  service：

一次性查表拿到内存里->并发计算每个页面的数据->返回

**年终项目工作流程**

* crawler：

首先在本地导入以下 `db.sql` 这个是数据库的表结构。也可以根据实际需要做修改。

负责人只要每月爬一次数据就行，改以下 `conf/config.yaml` 下的学号字段固定范围。

其中范围在下面有写，但是每年的新生都是没有范围的。这个需要你自己去给一个范围，然后去爬。

一般都是从`20xx210001`开始的。

配置文件的 `cokie` 每次爬都要从 `charles` 获取。具体文上一级的负责人。

爬完之后运行 `update.sql` 去更新数据，这个主要是改一些字段。每年餐厅会有变化，新变化就自己改一下。然后把修改也更新到 `update.sql` 里面。

* service：

接口方面每年需求不一样，这个只能你们自己写。也可以参考这个仓库的代码。

**stu2020**:

* 2019210001 - 2019215466

* 2018210001 - 2018215361

* 2017210001 - 2017215987

* 2020210001 - 2020214992